{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd3da36-e292-48cd-99ce-ef49087c650f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32833 entries, 0 to 32832\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   track_id                  32833 non-null  object \n",
      " 1   track_name                32828 non-null  object \n",
      " 2   track_artist              32828 non-null  object \n",
      " 3   track_popularity          32833 non-null  int64  \n",
      " 4   track_album_id            32833 non-null  object \n",
      " 5   track_album_name          32828 non-null  object \n",
      " 6   track_album_release_date  32833 non-null  object \n",
      " 7   playlist_name             32833 non-null  object \n",
      " 8   playlist_id               32833 non-null  object \n",
      " 9   playlist_genre            32833 non-null  object \n",
      " 10  playlist_subgenre         32833 non-null  object \n",
      " 11  danceability              32833 non-null  float64\n",
      " 12  energy                    32833 non-null  float64\n",
      " 13  key                       32833 non-null  int64  \n",
      " 14  loudness                  32833 non-null  float64\n",
      " 15  mode                      32833 non-null  int64  \n",
      " 16  speechiness               32833 non-null  float64\n",
      " 17  acousticness              32833 non-null  float64\n",
      " 18  instrumentalness          32833 non-null  float64\n",
      " 19  liveness                  32833 non-null  float64\n",
      " 20  valence                   32833 non-null  float64\n",
      " 21  tempo                     32833 non-null  float64\n",
      " 22  duration_ms               32833 non-null  int64  \n",
      "dtypes: float64(9), int64(4), object(10)\n",
      "memory usage: 5.8+ MB\n",
      "None\n",
      "                 track_id                                         track_name  \\\n",
      "0  6f807x0ima9a1j3VPbc7VN  I Don't Care (with Justin Bieber) - Loud Luxur...   \n",
      "1  0r7CVbZTWZgbTCYdfa2P31                    Memories - Dillon Francis Remix   \n",
      "2  1z1Hg7Vb0AhHDiEmnDE79l                    All the Time - Don Diablo Remix   \n",
      "3  75FpbthrwQmzHlBJLuGdC7                  Call You Mine - Keanu Silva Remix   \n",
      "4  1e8PAfcKUYoKkxPhrHqw4x            Someone You Loved - Future Humans Remix   \n",
      "\n",
      "       track_artist  track_popularity          track_album_id  \\\n",
      "0        Ed Sheeran                66  2oCs0DGTsRO98Gh5ZSl2Cx   \n",
      "1          Maroon 5                67  63rPSO264uRjW1X5E6cWv6   \n",
      "2      Zara Larsson                70  1HoSmj2eLcsrR0vE9gThr4   \n",
      "3  The Chainsmokers                60  1nqYsOef1yKKuGOVchbsk6   \n",
      "4     Lewis Capaldi                69  7m7vv9wlQ4i0LFuJiE2zsQ   \n",
      "\n",
      "                                    track_album_name track_album_release_date  \\\n",
      "0  I Don't Care (with Justin Bieber) [Loud Luxury...               2019-06-14   \n",
      "1                    Memories (Dillon Francis Remix)               2019-12-13   \n",
      "2                    All the Time (Don Diablo Remix)               2019-07-05   \n",
      "3                        Call You Mine - The Remixes               2019-07-19   \n",
      "4            Someone You Loved (Future Humans Remix)               2019-03-05   \n",
      "\n",
      "  playlist_name             playlist_id playlist_genre  ... key  loudness  \\\n",
      "0     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   6    -2.634   \n",
      "1     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...  11    -4.969   \n",
      "2     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   1    -3.432   \n",
      "3     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   7    -3.778   \n",
      "4     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   1    -4.672   \n",
      "\n",
      "   mode  speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
      "0     1       0.0583        0.1020          0.000000    0.0653    0.518   \n",
      "1     1       0.0373        0.0724          0.004210    0.3570    0.693   \n",
      "2     0       0.0742        0.0794          0.000023    0.1100    0.613   \n",
      "3     1       0.1020        0.0287          0.000009    0.2040    0.277   \n",
      "4     1       0.0359        0.0803          0.000000    0.0833    0.725   \n",
      "\n",
      "     tempo  duration_ms  \n",
      "0  122.036       194754  \n",
      "1   99.972       162600  \n",
      "2  124.008       176616  \n",
      "3  121.956       169093  \n",
      "4  123.976       189052  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aliahmed/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)]]\n",
      "[(0,\n",
      "  '0.050*\"good\" + 0.039*\"feel\" + 0.034*\"better\" + 0.034*\"party\" + 0.030*\"sun\" '\n",
      "  '+ 0.029*\"day\" + 0.028*\"im\" + 0.026*\"big\" + 0.022*\"knows\" + 0.021*\"without\"'),\n",
      " (1,\n",
      "  '0.169*\"remix\" + 0.093*\"mix\" + 0.061*\"original\" + 0.012*\"night\" + '\n",
      "  '0.012*\"one\" + 0.012*\"club\" + 0.010*\"go\" + 0.008*\"extended\" + 0.007*\"vs\" + '\n",
      "  '0.007*\"take\"'),\n",
      " (2,\n",
      "  '0.048*\"bad\" + 0.034*\"dawn\" + 0.026*\"war\" + 0.021*\"hours\" + 0.020*\"el\" + '\n",
      "  '0.017*\"five\" + 0.017*\"cold\" + 0.013*\"bebe\" + 0.013*\"rexha\" + '\n",
      "  '0.012*\"justin\"'),\n",
      " (3,\n",
      "  '0.098*\"dont\" + 0.071*\"life\" + 0.036*\"dance\" + 0.025*\"sweet\" + 0.023*\"lose\" '\n",
      "  '+ 0.023*\"control\" + 0.023*\"make\" + 0.021*\"wanna\" + 0.020*\"hands\" + '\n",
      "  '0.019*\"nothing\"'),\n",
      " (4,\n",
      "  '0.227*\"love\" + 0.051*\"get\" + 0.028*\"got\" + 0.024*\"beautiful\" + '\n",
      "  '0.018*\"found\" + 0.018*\"tonight\" + 0.018*\"could\" + 0.017*\"higher\" + '\n",
      "  '0.017*\"klaas\" + 0.016*\"kill\"'),\n",
      " (5,\n",
      "  '0.303*\"feat\" + 0.025*\"back\" + 0.022*\"way\" + 0.018*\"u\" + 0.012*\"steve\" + '\n",
      "  '0.012*\"know\" + 0.012*\"alive\" + 0.011*\"say\" + 0.010*\"house\" + 0.010*\"need\"'),\n",
      " (6,\n",
      "  '0.142*\"like\" + 0.065*\"lights\" + 0.051*\"world\" + 0.023*\"save\" + 0.020*\"x\" + '\n",
      "  '0.019*\"gervais\" + 0.019*\"cedric\" + 0.018*\"la\" + 0.018*\"side\" + '\n",
      "  '0.018*\"something\"'),\n",
      " (7,\n",
      "  '0.052*\"time\" + 0.045*\"tiÃ«sto\" + 0.043*\"mind\" + 0.034*\"summer\" + '\n",
      "  '0.028*\"last\" + 0.026*\"eyes\" + 0.026*\"want\" + 0.026*\"keep\" + 0.019*\"find\" + '\n",
      "  '0.017*\"feet\"'),\n",
      " (8,\n",
      "  '0.055*\"never\" + 0.049*\"let\" + 0.036*\"light\" + 0.034*\"chris\" + 0.029*\"turn\" '\n",
      "  '+ 0.028*\"romero\" + 0.027*\"music\" + 0.025*\"wont\" + 0.024*\"boy\" + '\n",
      "  '0.022*\"leave\"'),\n",
      " (9,\n",
      "  '0.336*\"edit\" + 0.286*\"radio\" + 0.022*\"version\" + 0.020*\"home\" + '\n",
      "  '0.017*\"vocal\" + 0.012*\"hardwell\" + 0.010*\"drop\" + 0.008*\"wake\" + '\n",
      "  '0.007*\"bring\" + 0.005*\"many\"')]\n",
      "LDA visualization saved as lda_vis.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from pprint import pprint\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/aliahmed/Downloads/archive/spotify_songs.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows and the columns of the dataset\n",
    "print(data.info())\n",
    "print(data.head())\n",
    "\n",
    "# Preprocess the track names\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "        text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
    "        text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
    "        text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()  # Replace multiple spaces with a single space\n",
    "        text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    else:\n",
    "        text = \"\"\n",
    "    return text\n",
    "\n",
    "data['cleaned_track_name'] = data['track_name'].apply(preprocess_text)\n",
    "\n",
    "# Tokenize the track names\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "data['tokens'] = data['cleaned_track_name'].apply(tokenize)\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data['tokens'])\n",
    "\n",
    "# Create Corpus\n",
    "texts = data['tokens']\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics=10, \n",
    "                                            random_state=100,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            alpha='auto',\n",
    "                                            per_word_topics=True)\n",
    "\n",
    "# Print the topics\n",
    "pprint(lda_model.print_topics())\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "pyLDAvis.save_html(vis, 'lda_vis.html')\n",
    "print(\"LDA visualization saved as lda_vis.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62651c85-b224-430e-9055-af2665a16f35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
